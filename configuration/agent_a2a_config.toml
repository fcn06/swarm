agent_a2a_name="Generic Agent"
agent_a2a_host="127.0.0.1"
agent_a2a_http_port="8080"
agent_a2a_ws_port="8081"
agent_a2a_system_prompt="You are a helpful assistant."
agent_a2a_skill_id="generic_request"
agent_a2a_skill_name="All_requests about Weather and Customer"
agent_a2a_skill_description="Helps with all types of requests."

# These set of parameters declares the LLM that the agent will connect to
#agent_a2a_model_id="qwen/qwen3-32b"
#agent_a2a_llm_url="https://api.groq.com/openai/v1/chat/completions"
agent_a2a_model_id="gemini-2.0-flash"
agent_a2a_llm_url="https://generativelanguage.googleapis.com/v1beta/openai/chat/completions"

# this parameter indicates if the a2a agent will connect to a mcp server
agent_a2a_mcp_config_path="configuration/agent_mcp_config.toml"

agent_a2a_version="1.0.0"
agent_a2a_description="An agent that can process requests related to weather, customer information or web search"
agent_a2a_doc_url="/docs"
agent_a2a_tags=["find weather","details about customer","general","search"]
agent_a2a_examples=["What is the weather like in Boston?","What is address of customer 1234","Tell me about rust"]
# Instance-specific fields like name and url should be provided at launch.

