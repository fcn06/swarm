#################################################################
# Config for Judge Agent
#################################################################

#################################################################
# General parameters
#################################################################
agent_name="Judge Agent"
agent_host="127.0.0.1"
agent_http_port="6000"

# Future use. Websocket is not supported
agent_ws_port="6001"

#################################################################
# Future use : It would make sense to have a discovery service
# so that planner agent can dynamically discover agents to
# connect to
#################################################################
agent_discovery_url="http://127.0.0.1:4000"


#################################################################
# Purpose and high level skills
# The agent will use the A2A protocol for his interactions
#################################################################
agent_system_prompt="You are a helpful assistant that answers user requests."
agent_skill_id="evaluation_agent"
agent_skill_name="Evaluation of the performance of Agents"
agent_skill_description="Helps with agent performance evaluation."
agent_version="1.0.0"
agent_description="An agent that can evaluate the relevance of agent response, and give advice to improve them"
agent_doc_url="/docs"
agent_tags=["llm_as_judge","evaluation"]
agent_examples=["How relevant was the answer of the agent"]

#################################################################
# Define her the url of openai compatible endpoint 
# as well as the model to use
#################################################################
# These set of parameters declares the LLM that the agent will connect to
#agent_model_id="gemini-2.0-flash"
#agent_llm_url="https://generativelanguage.googleapis.com/v1beta/openai/chat/completions"
#agent_model_id="qwen/qwen3-32b"
agent_model_id="openai/gpt-oss-20b"
#agent_model_id="deepseek-r1-distill-llama-70b"
#agent_model_id="meta-llama/llama-4-scout-17b-16e-instruct"
agent_llm_url="https://api.groq.com/openai/v1/chat/completions"

