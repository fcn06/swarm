#################################################################
# Config for A2A Agent, that can embed a MCP agent
#################################################################

#################################################################
# General parameters
#################################################################
agent_name="Workflow_Agent"
agent_host="127.0.0.1"
agent_http_port="8180"

# Future use. Websocket is not supported
agent_ws_port="8181"

#################################################################
# Future use : It would make sense to have a discovery service
# so that planner agent can dynamically discover agents to
# connect to
#################################################################
agent_discovery_url="http://127.0.0.1:4000"

#################################################################
# Agent Evaluation Service
#################################################################
agent_evaluation_service_url="http://127.0.0.1:7000"


#################################################################
# Purpose and high level skills
# The agent will use the A2A protocol for his interactions
#################################################################
agent_system_prompt="You are a helpful assistant that answers user requests."
agent_skill_id="workflow_processing"
agent_skill_name="Defining and Processing complex workflow through specific tasks, agents and tools"
agent_skill_description="Run complex workflow"
agent_version="1.0.0"
agent_description="An agent that can define and process complex workflow through specific tasks, agents and tools"
agent_doc_url="/docs"
agent_tags=["execute workflow","general"]
agent_examples=["What is the weather like in Boston?","What is address of customer 1234","Tell me about rust"]

#################################################################
# Define her the url of openai compatible endpoint 
# as well as the model to use
#################################################################
# These set of parameters declares the LLM that the agent will connect to
agent_model_id="gemini-2.0-flash"
agent_llm_url="https://generativelanguage.googleapis.com/v1beta/openai/chat/completions"
#agent_model_id="qwen/qwen3-32b"
#agent_model_id="openai/gpt-oss-20b"
#agent_model_id="deepseek-r1-distill-llama-70b"
#agent_model_id="meta-llama/llama-4-scout-17b-16e-instruct"
#agent_llm_url="https://api.groq.com/openai/v1/chat/completions"


#################################################################
# You can say the agent to include a MCP runtime agent
# you just define the configuration file to use
#################################################################
agent_mcp_config_path="documentation/demo_workflow_management/mcp_runtime_config.toml"
